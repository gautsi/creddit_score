{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.colors as cl\n",
      "import matplotlib.patches as mpatches\n",
      "import matplotlib.cm as cm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import creddit_score as cs\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import cross_validation\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn import metrics\n",
      "from scipy import interp\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "from sklearn.cross_validation import StratifiedKFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/gautam/anaconda/lib/python2.7/site-packages/pytz/__init__.py:35: UserWarning: Module argparse was already imported from /home/gautam/anaconda/lib/python2.7/argparse.pyc, but /home/gautam/anaconda/lib/python2.7/site-packages is being added to sys.path\n",
        "  from pkg_resources import resource_stream\n",
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:148: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:150: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:152: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._min_spanning_tree import minimum_spanning_tree\n",
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/special/__init__.py:531: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._ufuncs import *\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/spatial/__init__.py:90: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .ckdtree import *\n",
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/spatial/__init__.py:91: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .qhull import *\n",
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/stats/distributions.py:35: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import vonmises_cython\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/stats/stats.py:252: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._rank import rankdata, tiecorrect\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sqlalchemy import MetaData, create_engine\n",
      "from sqlalchemy.sql import select\n",
      "from sqlalchemy.exc import StatementError"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize(X):\n",
      "    mean = X.mean()\n",
      "    range_X = X.max() - X.min()\n",
      "    return (X - mean)/float(range_X), mean, range_X\n",
      "\n",
      "def denorm(norm, mean, range_X):\n",
      "    return mean + norm*range_X\n",
      "\n",
      "def cube_root(x):\n",
      "    if x > 0:\n",
      "        return x**(1.0/3.0)\n",
      "    else:\n",
      "        return -1*(-1*x)**(1.0/3.0)\n",
      "    \n",
      "def add_features(df, thresh=-1):\n",
      "    df['age'] = df.created - df.subm_created\n",
      "    df['age_min'] = df.age/60.0\n",
      "    df['age_min_log'] = np.log10(df.age_min)\n",
      "    df['time_since_post'] = df.timestamp - df.created\n",
      "    df['time_since_post_min'] = df.time_since_post/60.0\n",
      "    df['time_since_post_min_log'] = np.log10(df.time_since_post_min)\n",
      "    #df['color'] = df.subreddit.apply(lambda x : cs.subreddits.index(x))\n",
      "    df['comment_length'] = df.content.apply(len)\n",
      "    df['comment_num_words'] = df.content.apply(lambda x : len(x.split()))\n",
      "    df['comment_length_log'] = np.log10(df.comment_length)\n",
      "    df['comment_num_words_log'] = np.log10(df.comment_num_words)\n",
      "    df['subm_num_comments_log'] = np.log10(df.subm_num_comments)\n",
      "    #df['poor'] = df.score.apply(lambda x : -1 if x < thresh else 1)\n",
      "    df['cube_score'] = df.score.apply(lambda x : cube_root(x))\n",
      "    df['cube_subm_score'] = df.subm_score.apply(lambda x : cube_root(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dib_df = pd.read_sql(sql=\"select *\\\n",
      "                     from comm_subm\\\n",
      "                     where subreddit='DataIsBeautiful'\",                    \n",
      "                     con=cs.engine)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comments_most_recent = dib_df.groupby(dib_df.comment_id).last()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "add_features(comments_most_recent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normalized_scores, mean, range_X = normalize(comments_most_recent.cube_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "low_bound = normalized_scores.mean() - normalized_scores.std()\n",
      "high_bound = normalized_scores.mean() + normalized_scores.std()\n",
      "low_thresh = round(denorm(low_bound, mean, range_X)**3)\n",
      "high_thresh = round(denorm(high_bound, mean, range_X)**3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "low_thresh, high_thresh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 149,
       "text": [
        "(-0.0, 14.0)"
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "good = comments_most_recent[comments_most_recent.score < low_thresh]\n",
      "bad = comments_most_recent[comments_most_recent.score > high_thresh]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "good_bad = good.add"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "good_bad = good.add"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import word_tokenize          \n",
      "from nltk.stem import WordNetLemmatizer \n",
      "class LemmaTokenizer(object):\n",
      "    def __init__(self):\n",
      "        self.wnl = WordNetLemmatizer()\n",
      "    def __call__(self, doc):\n",
      "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_vect = CountVectorizer(ngram_range = (2,2), stop_words='english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = count_vect.fit_transform(comments_most_recent.content)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(count_vect.vocabulary_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 229,
       "text": [
        "365489"
       ]
      }
     ],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(comments_most_recent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 231,
       "text": [
        "24716"
       ]
      }
     ],
     "prompt_number": 231
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq_df = pd.DataFrame({\"ngram\" : count_vect.get_feature_names(), \"count\" : np.asarray(X.sum(axis=0)).ravel()})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq_df_good.sort('count', ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "      <th>n-gram</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>24413</th>\n",
        "      <td> 543</td>\n",
        "      <td>              people</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17837</th>\n",
        "      <td> 321</td>\n",
        "      <td>                just</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19279</th>\n",
        "      <td> 296</td>\n",
        "      <td>                like</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9507 </th>\n",
        "      <td> 290</td>\n",
        "      <td>                 don</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33765</th>\n",
        "      <td> 188</td>\n",
        "      <td>               think</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27671</th>\n",
        "      <td> 188</td>\n",
        "      <td>              reddit</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20452</th>\n",
        "      <td> 169</td>\n",
        "      <td>                make</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14408</th>\n",
        "      <td> 160</td>\n",
        "      <td>                  gt</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18380</th>\n",
        "      <td> 124</td>\n",
        "      <td>                know</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21924</th>\n",
        "      <td> 120</td>\n",
        "      <td>               money</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27424</th>\n",
        "      <td> 117</td>\n",
        "      <td>              really</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34135</th>\n",
        "      <td> 116</td>\n",
        "      <td>                time</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8698 </th>\n",
        "      <td> 108</td>\n",
        "      <td>                 did</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9350 </th>\n",
        "      <td> 106</td>\n",
        "      <td>               doesn</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36670</th>\n",
        "      <td> 105</td>\n",
        "      <td>                 way</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28634</th>\n",
        "      <td> 105</td>\n",
        "      <td>               right</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13888</th>\n",
        "      <td> 104</td>\n",
        "      <td>                good</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36387</th>\n",
        "      <td> 101</td>\n",
        "      <td>                want</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37364</th>\n",
        "      <td> 101</td>\n",
        "      <td>                work</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8294 </th>\n",
        "      <td>  98</td>\n",
        "      <td>             deleted</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29278</th>\n",
        "      <td>  97</td>\n",
        "      <td>                 say</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37539</th>\n",
        "      <td>  97</td>\n",
        "      <td>               world</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25362</th>\n",
        "      <td>  91</td>\n",
        "      <td>               point</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13774</th>\n",
        "      <td>  85</td>\n",
        "      <td>               going</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7791 </th>\n",
        "      <td>  84</td>\n",
        "      <td>                data</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12905</th>\n",
        "      <td>  84</td>\n",
        "      <td>                fuck</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30189</th>\n",
        "      <td>  83</td>\n",
        "      <td>                shit</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1191 </th>\n",
        "      <td>  82</td>\n",
        "      <td>            actually</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38008</th>\n",
        "      <td>  81</td>\n",
        "      <td>               years</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9282 </th>\n",
        "      <td>  79</td>\n",
        "      <td>                does</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13809</th>\n",
        "      <td>   1</td>\n",
        "      <td>          going help</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13808</th>\n",
        "      <td>   1</td>\n",
        "      <td>          going hell</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13807</th>\n",
        "      <td>   1</td>\n",
        "      <td>          going head</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13806</th>\n",
        "      <td>   1</td>\n",
        "      <td>          going hate</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13804</th>\n",
        "      <td>   1</td>\n",
        "      <td>         going group</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13803</th>\n",
        "      <td>   1</td>\n",
        "      <td>        going garner</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13802</th>\n",
        "      <td>   1</td>\n",
        "      <td>          going free</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13801</th>\n",
        "      <td>   1</td>\n",
        "      <td>         going flood</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13800</th>\n",
        "      <td>   1</td>\n",
        "      <td>    going exceptions</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13799</th>\n",
        "      <td>   1</td>\n",
        "      <td>       going dollars</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13798</th>\n",
        "      <td>   1</td>\n",
        "      <td>         going doing</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13797</th>\n",
        "      <td>   1</td>\n",
        "      <td>     going disappear</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13796</th>\n",
        "      <td>   1</td>\n",
        "      <td>        going defend</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13794</th>\n",
        "      <td>   1</td>\n",
        "      <td>      going decrease</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13779</th>\n",
        "      <td>   1</td>\n",
        "      <td>          going bake</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13793</th>\n",
        "      <td>   1</td>\n",
        "      <td>        going debate</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13792</th>\n",
        "      <td>   1</td>\n",
        "      <td>       going dealing</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13791</th>\n",
        "      <td>   1</td>\n",
        "      <td>          going data</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13790</th>\n",
        "      <td>   1</td>\n",
        "      <td> going confederation</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13789</th>\n",
        "      <td>   1</td>\n",
        "      <td>     going computers</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13788</th>\n",
        "      <td>   1</td>\n",
        "      <td>          going come</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13787</th>\n",
        "      <td>   1</td>\n",
        "      <td>       going college</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13786</th>\n",
        "      <td>   1</td>\n",
        "      <td>         going cheap</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13785</th>\n",
        "      <td>   1</td>\n",
        "      <td>     going challenge</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13784</th>\n",
        "      <td>   1</td>\n",
        "      <td>         going cause</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13783</th>\n",
        "      <td>   1</td>\n",
        "      <td>        going casual</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13782</th>\n",
        "      <td>   1</td>\n",
        "      <td>          going burb</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13781</th>\n",
        "      <td>   1</td>\n",
        "      <td>      going bankrupt</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13780</th>\n",
        "      <td>   1</td>\n",
        "      <td>     going baltimore</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38222</th>\n",
        "      <td>   1</td>\n",
        "      <td>         zwv3xvhaqsc</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>38223 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 225,
       "text": [
        "       count               n-gram\n",
        "24413    543               people\n",
        "17837    321                 just\n",
        "19279    296                 like\n",
        "9507     290                  don\n",
        "33765    188                think\n",
        "27671    188               reddit\n",
        "20452    169                 make\n",
        "14408    160                   gt\n",
        "18380    124                 know\n",
        "21924    120                money\n",
        "27424    117               really\n",
        "34135    116                 time\n",
        "8698     108                  did\n",
        "9350     106                doesn\n",
        "36670    105                  way\n",
        "28634    105                right\n",
        "13888    104                 good\n",
        "36387    101                 want\n",
        "37364    101                 work\n",
        "8294      98              deleted\n",
        "29278     97                  say\n",
        "37539     97                world\n",
        "25362     91                point\n",
        "13774     85                going\n",
        "7791      84                 data\n",
        "12905     84                 fuck\n",
        "30189     83                 shit\n",
        "1191      82             actually\n",
        "38008     81                years\n",
        "9282      79                 does\n",
        "...      ...                  ...\n",
        "13809      1           going help\n",
        "13808      1           going hell\n",
        "13807      1           going head\n",
        "13806      1           going hate\n",
        "13804      1          going group\n",
        "13803      1         going garner\n",
        "13802      1           going free\n",
        "13801      1          going flood\n",
        "13800      1     going exceptions\n",
        "13799      1        going dollars\n",
        "13798      1          going doing\n",
        "13797      1      going disappear\n",
        "13796      1         going defend\n",
        "13794      1       going decrease\n",
        "13779      1           going bake\n",
        "13793      1         going debate\n",
        "13792      1        going dealing\n",
        "13791      1           going data\n",
        "13790      1  going confederation\n",
        "13789      1      going computers\n",
        "13788      1           going come\n",
        "13787      1        going college\n",
        "13786      1          going cheap\n",
        "13785      1      going challenge\n",
        "13784      1          going cause\n",
        "13783      1         going casual\n",
        "13782      1           going burb\n",
        "13781      1       going bankrupt\n",
        "13780      1      going baltimore\n",
        "38222      1          zwv3xvhaqsc\n",
        "\n",
        "[38223 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq_df_bad.sort('count', ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "      <th>n-gram</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>28784</th>\n",
        "      <td> 524</td>\n",
        "      <td>                people</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21139</th>\n",
        "      <td> 347</td>\n",
        "      <td>                  just</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22687</th>\n",
        "      <td> 317</td>\n",
        "      <td>                  like</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7837 </th>\n",
        "      <td> 222</td>\n",
        "      <td>                   com</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11850</th>\n",
        "      <td> 212</td>\n",
        "      <td>                   don</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19061</th>\n",
        "      <td> 210</td>\n",
        "      <td>                 https</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19026</th>\n",
        "      <td> 191</td>\n",
        "      <td>                  http</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32572</th>\n",
        "      <td> 186</td>\n",
        "      <td>                reddit</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17273</th>\n",
        "      <td> 184</td>\n",
        "      <td>                    gt</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39781</th>\n",
        "      <td> 184</td>\n",
        "      <td>                  time</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44425</th>\n",
        "      <td> 177</td>\n",
        "      <td>                   www</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39409</th>\n",
        "      <td> 170</td>\n",
        "      <td>                 think</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44828</th>\n",
        "      <td> 158</td>\n",
        "      <td>               youtube</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32275</th>\n",
        "      <td> 142</td>\n",
        "      <td>                really</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24248</th>\n",
        "      <td> 141</td>\n",
        "      <td>                  make</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27858</th>\n",
        "      <td> 131</td>\n",
        "      <td>                   org</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43695</th>\n",
        "      <td> 124</td>\n",
        "      <td>             wikipedia</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25877</th>\n",
        "      <td> 123</td>\n",
        "      <td>                 money</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43578</th>\n",
        "      <td> 123</td>\n",
        "      <td>                  wiki</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16680</th>\n",
        "      <td> 122</td>\n",
        "      <td>                  good</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12937</th>\n",
        "      <td> 119</td>\n",
        "      <td>                    en</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43947</th>\n",
        "      <td> 117</td>\n",
        "      <td>                  work</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21745</th>\n",
        "      <td> 117</td>\n",
        "      <td>                  know</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2861 </th>\n",
        "      <td> 116</td>\n",
        "      <td>                   amp</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42964</th>\n",
        "      <td> 116</td>\n",
        "      <td>                 watch</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27870</th>\n",
        "      <td> 116</td>\n",
        "      <td>              org wiki</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43704</th>\n",
        "      <td> 113</td>\n",
        "      <td>         wikipedia org</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12942</th>\n",
        "      <td> 113</td>\n",
        "      <td>          en wikipedia</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16544</th>\n",
        "      <td> 109</td>\n",
        "      <td>                 going</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23819</th>\n",
        "      <td> 106</td>\n",
        "      <td>                   lot</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19533</th>\n",
        "      <td>   1</td>\n",
        "      <td>         implies women</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4342 </th>\n",
        "      <td>   1</td>\n",
        "      <td>        banned snowden</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19535</th>\n",
        "      <td>   1</td>\n",
        "      <td>       imply sarcastic</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19536</th>\n",
        "      <td>   1</td>\n",
        "      <td>              imply uk</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19537</th>\n",
        "      <td>   1</td>\n",
        "      <td>              implying</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19538</th>\n",
        "      <td>   1</td>\n",
        "      <td>       implying deaths</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4341 </th>\n",
        "      <td>   1</td>\n",
        "      <td>        banned smaller</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19540</th>\n",
        "      <td>   1</td>\n",
        "      <td>     import scientists</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19541</th>\n",
        "      <td>   1</td>\n",
        "      <td>     import subsidized</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4340 </th>\n",
        "      <td>   1</td>\n",
        "      <td>          banned small</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19543</th>\n",
        "      <td>   1</td>\n",
        "      <td>       important agree</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4343 </th>\n",
        "      <td>   1</td>\n",
        "      <td>      banned subreddit</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19527</th>\n",
        "      <td>   1</td>\n",
        "      <td>   implications policy</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19526</th>\n",
        "      <td>   1</td>\n",
        "      <td>          implications</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19517</th>\n",
        "      <td>   1</td>\n",
        "      <td>      imperial revenue</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19511</th>\n",
        "      <td>   1</td>\n",
        "      <td>           impaler aka</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19512</th>\n",
        "      <td>   1</td>\n",
        "      <td>              impeding</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19513</th>\n",
        "      <td>   1</td>\n",
        "      <td>          impeding new</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4347 </th>\n",
        "      <td>   1</td>\n",
        "      <td>     banned supposedly</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4346 </th>\n",
        "      <td>   1</td>\n",
        "      <td>     banned suggesting</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19516</th>\n",
        "      <td>   1</td>\n",
        "      <td>       imperial german</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19518</th>\n",
        "      <td>   1</td>\n",
        "      <td>             implement</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19525</th>\n",
        "      <td>   1</td>\n",
        "      <td>       implication got</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19519</th>\n",
        "      <td>   1</td>\n",
        "      <td>         implement hsr</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4345 </th>\n",
        "      <td>   1</td>\n",
        "      <td>           banned subs</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19521</th>\n",
        "      <td>   1</td>\n",
        "      <td>          implementing</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19522</th>\n",
        "      <td>   1</td>\n",
        "      <td> implementing websites</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4344 </th>\n",
        "      <td>   1</td>\n",
        "      <td>     banned subreddits</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19524</th>\n",
        "      <td>   1</td>\n",
        "      <td>    implication aliens</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44954</th>\n",
        "      <td>   1</td>\n",
        "      <td>           zwurp8s png</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>44955 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 226,
       "text": [
        "       count                 n-gram\n",
        "28784    524                 people\n",
        "21139    347                   just\n",
        "22687    317                   like\n",
        "7837     222                    com\n",
        "11850    212                    don\n",
        "19061    210                  https\n",
        "19026    191                   http\n",
        "32572    186                 reddit\n",
        "17273    184                     gt\n",
        "39781    184                   time\n",
        "44425    177                    www\n",
        "39409    170                  think\n",
        "44828    158                youtube\n",
        "32275    142                 really\n",
        "24248    141                   make\n",
        "27858    131                    org\n",
        "43695    124              wikipedia\n",
        "25877    123                  money\n",
        "43578    123                   wiki\n",
        "16680    122                   good\n",
        "12937    119                     en\n",
        "43947    117                   work\n",
        "21745    117                   know\n",
        "2861     116                    amp\n",
        "42964    116                  watch\n",
        "27870    116               org wiki\n",
        "43704    113          wikipedia org\n",
        "12942    113           en wikipedia\n",
        "16544    109                  going\n",
        "23819    106                    lot\n",
        "...      ...                    ...\n",
        "19533      1          implies women\n",
        "4342       1         banned snowden\n",
        "19535      1        imply sarcastic\n",
        "19536      1               imply uk\n",
        "19537      1               implying\n",
        "19538      1        implying deaths\n",
        "4341       1         banned smaller\n",
        "19540      1      import scientists\n",
        "19541      1      import subsidized\n",
        "4340       1           banned small\n",
        "19543      1        important agree\n",
        "4343       1       banned subreddit\n",
        "19527      1    implications policy\n",
        "19526      1           implications\n",
        "19517      1       imperial revenue\n",
        "19511      1            impaler aka\n",
        "19512      1               impeding\n",
        "19513      1           impeding new\n",
        "4347       1      banned supposedly\n",
        "4346       1      banned suggesting\n",
        "19516      1        imperial german\n",
        "19518      1              implement\n",
        "19525      1        implication got\n",
        "19519      1          implement hsr\n",
        "4345       1            banned subs\n",
        "19521      1           implementing\n",
        "19522      1  implementing websites\n",
        "4344       1      banned subreddits\n",
        "19524      1     implication aliens\n",
        "44954      1            zwurp8s png\n",
        "\n",
        "[44955 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq_df_bad[freq_df_bad]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analyze = count_vect.build_analyzer()\n",
      "prepro = count_vect.build_preprocessor()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prepro(comments_most_recent.content[20])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "'makes me cringe seeing those country codes that they made up. sw != switzerland and ch != china.'"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(good_bad)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "low_bound, high_bound"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "(-0.057695807666502293, 0.057695807666502293)"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(abs(scores2 - comments_most_recent.score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "5.6736837450444e-12"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(comments_most_recent[comments_most_recent.score >= -76])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "76442"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/io/matlab/mio4.py:18: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .mio_utils import squeeze_element, chars_to_strings\n",
        "/home/gautam/anaconda/lib/python2.7/site-packages/scipy/io/matlab/mio5.py:98: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .mio5_utils import VarReader5\n"
       ]
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem import WordNetLemmatizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}